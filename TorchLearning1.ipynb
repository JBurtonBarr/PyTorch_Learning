{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#torch will be reliant on the np datastructure for tensors\n",
    "\n",
    "#We want to initialise our tensor by offering data to a numpy array and then parsing that array into torch\n",
    "\n",
    "data = [[1, 2, 3],[3, 4, 5], [2, 2, 1],[5, 2, 3]]\n",
    "#we could do torch_data = torch.tensor(data) this is more direct\n",
    "# more often that not though our data will be in a numpy array\n",
    "\n",
    "np_a = np.array(data)\n",
    "tensor_np = torch.from_numpy(np_a) #good\n",
    "#2\n",
    "\n",
    "#we can make a shape and datatype like tensor from another tensor\n",
    "datashapeclone = torch.ones_like(tensor_np) #will be filled with 1's\n",
    "#random clone \n",
    "datashapeclone_rand = torch.rand_like(tensor_np, dtype = torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7639, 0.1777, 0.0180],\n",
      "        [0.0364, 0.7276, 0.8171],\n",
      "        [0.9033, 0.3476, 0.6448],\n",
      "        [0.5023, 0.7129, 0.1092]])\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5],\n",
      "        [2, 2, 1],\n",
      "        [5, 2, 3]], dtype=torch.int32)\n",
      "Shape of tensor: torch.Size([4, 3])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(datashapeclone_rand)\n",
    "print(tensor_np)\n",
    "#the chape of these tensors are all 4 by 3\n",
    "#so the tensor is a shaped object that holds our data for ML\n",
    "print(f\"Shape of tensor: {tensor_np.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_np.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_np.device}\") #this is just getting tensor info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# we want to check that our GPU is available for our tensor operations \n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "  tensor_np = tensor_np.to('cuda')\n",
    "  #This will check if cuda is available and then move our tensor to cuda if so\n",
    "  # avoids a running error when cuda is not available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device tensor is stored on: {tensor_np.device}\")\n",
    "#Our tensor should now be stored on Cuda meaning GPU is accessable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [3, 4, 5, 3, 4, 5],\n",
      "        [2, 2, 1, 2, 2, 1],\n",
      "        [5, 2, 3, 5, 2, 3]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor_np, tensor_np], dim=1)\n",
    "print(t1)\n",
    "#notice how this will combine tensors along one dimension\n",
    "#we can also just STACK these "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Notes\n",
    "Tensors can be multiplied (look up when needed)\n",
    "We can also calculate matrix multiplication if needed (tensor.matmul(tensor.T2))\n",
    "\n",
    "We can convert our tensor back to nump with T1.numpy()\n",
    "Remember from_numpy is numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 6, 4, 5, 6],\n",
      "        [6, 7, 8, 6, 7, 8],\n",
      "        [5, 5, 4, 5, 5, 4],\n",
      "        [8, 5, 6, 8, 5, 6]], device='cuda:0', dtype=torch.int32) \n",
      "\n",
      "tensor([[ 7,  8,  9,  7,  8,  9],\n",
      "        [ 9, 10, 11,  9, 10, 11],\n",
      "        [ 8,  8,  7,  8,  8,  7],\n",
      "        [11,  8,  9, 11,  8,  9]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t1, \"\\n\")\n",
    "t1.add_(3)\n",
    "print(t1)\n",
    "#This will add 3 TO EVERY DATAPOINT WITHIN TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
