{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-70cc9d14d06b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#torch will be reliant on the np datastructure for tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#We want to initialise our tensor by offering data to a numpy array and then parsing that array into torch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#torch will be reliant on the np datastructure for tensors\n",
    "\n",
    "#We want to initialise our tensor by offering data to a numpy array and then parsing that array into torch\n",
    "\n",
    "data = [[1, 2, 3],[3, 4, 5], [2, 2, 1],[5, 2, 3]]\n",
    "#we could do torch_data = torch.tensor(data) this is more direct\n",
    "# more often that not though our data will be in a numpy array\n",
    "\n",
    "np_a = np.array(data)\n",
    "tensor_np = torch.from_numpy(np_a) #good\n",
    "\n",
    "\n",
    "#we can make a shape and datatype like tensor from another tensor\n",
    "datashapeclone = torch.ones_like(tensor_np) #will be filled with 1's\n",
    "#random clone \n",
    "datashapeclone_rand = torch.rand_like(tensor_np, dtype = torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7639, 0.1777, 0.0180],\n",
      "        [0.0364, 0.7276, 0.8171],\n",
      "        [0.9033, 0.3476, 0.6448],\n",
      "        [0.5023, 0.7129, 0.1092]])\n",
      "tensor([[1, 2, 3],\n",
      "        [3, 4, 5],\n",
      "        [2, 2, 1],\n",
      "        [5, 2, 3]], dtype=torch.int32)\n",
      "Shape of tensor: torch.Size([4, 3])\n",
      "Datatype of tensor: torch.int32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(datashapeclone_rand)\n",
    "print(tensor_np)\n",
    "#the chape of these tensors are all 4 by 3\n",
    "#so the tensor is a shaped object that holds our data for ML\n",
    "print(f\"Shape of tensor: {tensor_np.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor_np.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor_np.device}\") #this is just getting tensor info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# we want to check that our GPU is available for our tensor operations \n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "  tensor_np = tensor_np.to('cuda')\n",
    "  #This will check if cuda is available and then move our tensor to cuda if so\n",
    "  # avoids a running error when cuda is not available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device tensor is stored on: {tensor_np.device}\")\n",
    "#Our tensor should now be stored on Cuda meaning GPU is accessable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 1, 2, 3],\n",
      "        [3, 4, 5, 3, 4, 5],\n",
      "        [2, 2, 1, 2, 2, 1],\n",
      "        [5, 2, 3, 5, 2, 3]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor_np, tensor_np], dim=1)\n",
    "print(t1)\n",
    "#notice how this will combine tensors along one dimension\n",
    "#we can also just STACK these "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Notes\n",
    "Tensors can be multiplied (look up when needed)\n",
    "We can also calculate matrix multiplication if needed (tensor.matmul(tensor.T2))\n",
    "\n",
    "We can convert our tensor back to nump with T1.numpy()\n",
    "\n",
    "Remember from_numpy is numpy to tensor\n",
    "\n",
    "Changes in the NumPy array reflects in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5, 6, 4, 5, 6],\n",
      "        [6, 7, 8, 6, 7, 8],\n",
      "        [5, 5, 4, 5, 5, 4],\n",
      "        [8, 5, 6, 8, 5, 6]], device='cuda:0', dtype=torch.int32) \n",
      "\n",
      "tensor([[ 7,  8,  9,  7,  8,  9],\n",
      "        [ 9, 10, 11,  9, 10, 11],\n",
      "        [ 8,  8,  7,  8,  8,  7],\n",
      "        [11,  8,  9, 11,  8,  9]], device='cuda:0', dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t1, \"\\n\")\n",
    "t1.add_(3)\n",
    "print(t1)\n",
    "#This will add 3 TO EVERY DATAPOINT WITHIN TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TORCH.AUTOGRAD INTRO\n",
    "torch.autograd is PyTorchâ€™s automatic differentiation engine that powers neural network training\n",
    "\n",
    "### Forward Propagation: \n",
    "In forward prop, the NN makes its best guess about the correct output. It runs the input data through each of its functions to make this guess.\n",
    "\n",
    "### Backward Propagation: \n",
    "In backprop, the NN adjusts its parameters proportionate to the error in its guess. It does this by traversing backwards from the output, collecting the derivatives of the error with respect to the parameters of the functions (gradients), and optimizing the parameters using gradient descent. For a more detailed walkthrough of backprop\n",
    "    - Where a huge difference from the human brain occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa33de5e17f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#our moodel is one of torchvisions pretrained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.resnet18(pretrained=True) \n",
    "#our moodel is one of torchvisions pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = torch.rand(1, 3, 64, 64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
